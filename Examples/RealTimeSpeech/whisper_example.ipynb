{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qywu/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-02 16:10:25.520033: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-02 16:10:25.982717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-02 16:10:25.982759: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-02 16:10:25.982763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "\n",
    "from transformers import AutoProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASR:\n",
    "    def __init__(self) -> None:\n",
    "        model_name = \"openai/whisper-medium\"\n",
    "        self.processor = AutoProcessor.from_pretrained(model_name)\n",
    "        self.model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
    "        self.model_sample_rate = 16000\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "    def __call__(self, data, sample_rate=16000) -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: PCM float32 format\n",
    "            sample_rate: the sample rate of data\n",
    "        \"\"\"\n",
    "        # first, resample the data to the model's sample_rate\n",
    "        number_of_samples = round(len(data) * float(self.model_sample_rate) / sample_rate)\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "\n",
    "        # genearte text\n",
    "        inputs = self.processor(data, return_tensors=\"pt\", sampling_rate=self.model_sample_rate)\n",
    "        input_features = inputs.input_features.to(self.device)\n",
    "        generated_ids = self.model.generate(inputs=input_features)\n",
    "        text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0].strip()\n",
    "\n",
    "        return text \n",
    "\n",
    "    def to(self, device):\n",
    "        self.model = self.model.to(device)\n",
    "        self.device = device\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ASR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the running device\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wavfile.read(\"test.wav\")\n",
    "# requires float32 data\n",
    "data = data.astype(np.float32) / 32768.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The birch canoe slid on the smooth planks. Glue the sheet to the dark blue background. It is easy to tell the depth of a well. These days a chicken leg is a rare dish. Rice is often served in round bowls. The juice of lemons makes fine punch. The box was thrown beside the park truck. The hogs were fed chopped corn and garbage. Four hours of steady work faced us.\n"
     ]
    }
   ],
   "source": [
    "text = model(data, sample_rate=rate)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7911a035b20ade8406fa4e243b59abc26dd1e7c24f5f6090f8c665d0ff5a60b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
